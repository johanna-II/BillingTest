name: Nightly Regression Tests

# Purpose: Multi-config integration testing for regression detection
# Scope: Integration tests across countries (kr/jp/etc) and time periods
# Note: Unit tests run in PR CI, not here (avoid duplication)

on:
  schedule:
    # Run at 2 AM UTC every day (11 AM KST)
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      include_performance:
        description: 'Include performance tests'
        required: false
        default: false
        type: boolean

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  PYTHON_VERSION: '3.12'
  POETRY_VERSION: '2.2.1'

jobs:
  # Integration tests ONLY - member/month matrix for regression
  # Unit tests already run in PR CI (ci.yml) - no need to duplicate

  # Integration tests with matrix - member/month dependent
  integration-test-suite:
    name: Integration - ${{ matrix.member }} (${{ matrix.month }})
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        member: [kr, jp, etc]
        month: ['current', 'previous']

    steps:
      - name: Checkout code
        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8  # v5.0.0

      - name: Set test month
        id: set-month
        run: |
          if [[ "${{ matrix.month }}" = "current" ]]; then
            echo "MONTH=$(date +%Y-%m)" >> $GITHUB_OUTPUT
          else
            echo "MONTH=$(date -d "1 month ago" +%Y-%m)" >> $GITHUB_OUTPUT
          fi

      - name: Set up Python
        uses: actions/setup-python@e797f83bcb11b83ae66e0230d6156d7c80228e7c  # v6.0.0
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install Poetry
        uses: snok/install-poetry@76e04a911780d5b312d89783f7b1cd627778900a  # v1.4.1
        with:
          version: ${{ env.POETRY_VERSION }}

      - name: Install dependencies
        run: poetry install --no-interaction --with test,dev

      - name: Run integration & contract tests (Parallel)
        run: |
          # Integration and contract tests need member/month context
          # Run in parallel for speed (3-4x faster)
          poetry run pytest tests/integration/ tests/contracts/ \
            --env alpha \
            --member ${{ matrix.member }} \
            --month ${{ steps.set-month.outputs.MONTH }} \
            --cov=libs \
            --cov-report=xml:coverage-${{ matrix.member }}-${{ matrix.month }}.xml \
            --junit-xml=test-results-${{ matrix.member }}-${{ matrix.month }}.xml \
            -n auto \
            --dist=loadfile \
            --maxfail=5 \
            -v
        continue-on-error: true
        env:
          PYTEST_XDIST_AUTO_NUM_WORKERS: 4

      - name: Upload test results
        uses: actions/upload-artifact@330a01c490aca151604b8cf639adc76d48f6c5d4  # v5.0.0
        if: always()
        with:
          name: test-results-${{ matrix.member }}-${{ matrix.month }}
          path: test-results-*.xml

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@5a1091511ad55cbe89839c7260b706298ca349f7  # v5.5.1
        with:
          files: ./coverage-${{ matrix.member }}-${{ matrix.month }}.xml
          flags: scheduled,integration,${{ matrix.member }},${{ matrix.month }}
          name: integration-${{ matrix.member }}-${{ matrix.month }}
          fail_ci_if_error: false

  # Performance benchmark tests (Optional - weekly or on-demand)
  performance-tests:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    # Only run if manually triggered with include_performance=true
    # or on Mondays (weekly performance baseline)
    if: github.event.inputs.include_performance == 'true' || github.event.schedule == '0 2 * * 1'

    steps:
      - name: Checkout code
        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8  # v5.0.0

      - name: Set up Python
        uses: actions/setup-python@e797f83bcb11b83ae66e0230d6156d7c80228e7c  # v6.0.0
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install Poetry
        uses: snok/install-poetry@76e04a911780d5b312d89783f7b1cd627778900a  # v1.4.1
        with:
          version: ${{ env.POETRY_VERSION }}

      - name: Install dependencies
        run: poetry install --no-interaction --with test,dev

      - name: Start Mock Server
        run: |
          # Must use 'poetry run' to access virtualenv with flask
          poetry run python -m mock_server.run_server &
          MOCK_PID=$!
          echo "Mock server started with PID: $MOCK_PID"

          # Wait for server to be ready
          for i in {1..30}; do
            if curl -s --max-time 2 http://localhost:5000/health > /dev/null 2>&1; then
              echo "✓ Mock server is ready"
              break
            fi
            if [[ $i -eq 30 ]]; then
              echo "✗ Mock server failed to start"
              exit 1
            fi
            echo "Waiting for mock server... ($i/30)"
            sleep 1
          done
        env:
          FLASK_ENV: production
          MOCK_SERVER_RATE_LIMIT: 500

      - name: Run performance tests (Sequential - Locust requires it)
        run: |
          # Performance/locust tests MUST run sequentially (no -n flag)
          # Locust uses gevent which conflicts with pytest-xdist
          poetry run pytest tests/performance/ -v \
            --timeout=300 \
            --benchmark-only \
            --benchmark-json=performance-results.json \
            --benchmark-autosave \
            --junit-xml=performance-test-results.xml
        continue-on-error: true
        env:
          USE_MOCK_SERVER: 'true'
          MOCK_SERVER_URL: http://localhost:5000
          MOCK_SERVER_PORT: '5000'

      - name: Upload performance results
        uses: actions/upload-artifact@330a01c490aca151604b8cf639adc76d48f6c5d4  # v5.0.0
        if: always()
        with:
          name: performance-results
          path: |
            performance-results.json
            .benchmarks/

  # Note: Security scan runs in separate security.yml workflow (weekly on Mondays)

  # Test report summary
  test-summary:
    name: Nightly Regression Summary
    runs-on: ubuntu-latest
    needs: [integration-test-suite, performance-tests]
    if: always()

    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@018cc2cf5baa6db3ef3c5f8a56943fffe632ef53  # v6.0.0

      - name: Generate summary report
        run: |
          echo "# 🌙 Nightly Regression Test Report - $(date)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          echo "## Test Suite Results" >> $GITHUB_STEP_SUMMARY
          echo "- Integration Tests (Multi-config): ${{ needs.integration-test-suite.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Performance Tests (Weekly): ${{ needs.performance-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          echo "## Scope & Strategy" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Integration tests: 80 tests × 6 configs = 480 test runs" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Parallel execution: -n auto (3-4x speedup)" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Multi-tenant: kr/jp/etc countries" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Time-based: current + previous month" >> $GITHUB_STEP_SUMMARY
          echo "- ⚡ Expected time: ~18-20min" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Note" >> $GITHUB_STEP_SUMMARY
          echo "- Unit tests (2,465) run in PR CI, not here (avoid duplication)" >> $GITHUB_STEP_SUMMARY
          echo "- Security scan runs weekly in security.yml workflow" >> $GITHUB_STEP_SUMMARY
          echo "- Performance tests run weekly on Mondays only" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Parse test results if available
          if [[ -f "test-results-kr-current/test-results-kr-current.xml" ]]; then
            echo "## Test Metrics" >> $GITHUB_STEP_SUMMARY
            echo "Processing test results..." >> $GITHUB_STEP_SUMMARY
          fi

      - name: Notify on failure
        if: failure()
        run: |
          echo "❌ Scheduled tests failed! Check the results above." >> $GITHUB_STEP_SUMMARY
